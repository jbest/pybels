{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d5c55b-a50b-4051-8c93-320ba4fa31d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Loads a CSV DwC occurrence file that has been augmented with BELS locality strings\\n# based on some processes in analyze_loc_matches_local.ipynb\\n# focusing on summarization to help select candidate counties\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Loads a CSV DwC occurrence file that has been augmented with BELS locality strings\n",
    "# based on some processes in analyze_loc_matches_local.ipynb\n",
    "# focusing on summarization to help select candidate counties\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61251ce-f28e-4241-b613-cf19bff315a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7962e2-b7e9-4fce-9e68-abf3139f9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_path = '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/data/TORCH-data_snapshots_TX_OK_2024-12-06/'\n",
    "input_path = '/media/jbest/data3/BRIT_git/TORCH_georeferencing/data/TORCH-data_snapshots_TX_OK_2024-12-06/'\n",
    "input_filename = 'torch_bels_metrics.tsv'\n",
    "bels_locs_path = Path(input_path) / input_filename\n",
    "#bels_locs_path = '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/data/TORCH-data_snapshots_TX_OK_2024-12-06/torch_bels_locs.tsv'\n",
    "#df_occ = pd.read_csv(bels_locs_path, low_memory=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70cc0bc-3e4d-46fb-8aa9-113e88d21fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data with BELS augmentation/metrics\n",
    "df_occ = pd.read_csv(bels_locs_path, low_memory=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3de6262-33d4-4dc4-a292-92b759b36714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1146433, 124)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4b35d4-dd6d-4de5-a3fa-5809c4638bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant colums\n",
    "# NOTE not all of these columns occur across all collections\n",
    "drop_columns= ['higherClassification','kingdom','phylum','class','order','identificationReferences','identificationRemarks','taxonRemarks','identificationQualifier','typeStatus','fieldNumber','eventID','informationWithheld','dataGeneralizations','dynamicProperties','associatedSequences','associatedTaxa','reproductiveCondition','establishmentMeans','lifeStage','sex','individualCount','samplingProtocol','preparations','continent','waterBody','islandGroup','island','rights','rightsHolder','accessRights','recordID','type','license','bibliographicCitation','datasetName','fieldNotes','countryCode','nomenclaturalCode','nomenclaturalStatus','associatedMedia','higherGeography','institutionID','georeferencedDate','datasetID','occurrenceStatus','verbatimLocality','organismID','previousIdentifications','eventTime','eventRemarks','locationAccordingTo','verbatimCoordinateSystem','footprintWKT','earliestEonOrLowestEonothem','earliestEraOrLowestErathem','earliestPeriodOrLowestSystem','earliestEpochOrLowestSeries','earliestAgeOrLowestStage','group','formation','member','identificationVerificationStatus','scientificNameID']\n",
    "df_occ = df_occ.drop(columns=drop_columns, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ce3fd1-65a5-4901-b8a6-c7a74eb54116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1146433, 67)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ad9ef1-d969-420a-bf3a-41a760f6faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate records\n",
    "df_matches = df_occ[df_occ['bels_location_string'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf6483c-299c-4640-8a3d-65af99aaebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812448, 67)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e272de-5508-4d96-8a46-4dbeb4bf53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add location ID\n",
    "# first create a copy to avoid copy of a slice of a DF\n",
    "df_matches = df_matches.copy()\n",
    "# https://stackoverflow.com/a/51110197 or https://stackoverflow.com/a/51110205\n",
    "df_matches['loc_id'] = df_matches.groupby(['bels_location_string']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ff8d1a-59f4-486b-9c48-00d347f4656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dup loc count column for the size of each location cluster (number of duplicate locations)\n",
    "#https://stackoverflow.com/a/46768694\n",
    "#TODO - better name and documentation?\\\n",
    "df_matches['dup_loc_count'] = df_matches.groupby(['bels_location_string']).transform('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5814dd-3986-46a7-b550-264c05a9e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original DataFrame:\n",
      "(812448, 69)\n",
      "\n",
      "Filtered DataFrame (locations with at least one set of coordinates):\n",
      "(500081, 70)\n"
     ]
    }
   ],
   "source": [
    "# find groups that have at least one georeference\n",
    "# from https://claude.ai/chat/f9eab37d-6cc0-459c-9d24-fd78d6152d10\n",
    "\n",
    "def filter_locations_with_coordinates(df):\n",
    "    \"\"\"\n",
    "    Filter location groups based on having at least one record with coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with location_string and coordinates columns\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Filtered DataFrame containing all records from location groups\n",
    "                     that have at least one set of coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the number of coordinates for each location group\n",
    "    coord_counts = df[df['decimalLatitude'].notna() & (df['decimalLatitude'] != '')].groupby('bels_location_string').size()\n",
    "\n",
    "    # Find locations that have at least one non-empty coordinates value\n",
    "    # This handles various types of \"empty\" values (None, NaN, empty string)\n",
    "    #locations_with_coords = df[df['decimalLatitude'].notna() & (df['decimalLatitude'] != '')]['bels_location_string'].unique()\n",
    "    \n",
    "    # Find locations that have at least one non-empty coordinates value\n",
    "    # changed approach now that we have coord_counts\n",
    "    locations_with_coords = coord_counts.index\n",
    "    \n",
    "    # Filter the original DataFrame to keep all records from matching locations\n",
    "    #filtered_df = df[df['bels_location_string'].isin(locations_with_coords)]\n",
    "    # (New approach) Filter the original DataFrame to keep all records from matching locations\n",
    "    filtered_df = df[df['bels_location_string'].isin(locations_with_coords)].copy()\n",
    "\n",
    "    # Add the coordinate count for each location\n",
    "    filtered_df['recs_w_geo_count'] = filtered_df['bels_location_string'].map(coord_counts)\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Filter locations that have at least one set of coordinates\n",
    "#result = filter_locations_with_coordinates(df)\n",
    "df_matches_w_geo = filter_locations_with_coordinates(df_matches)\n",
    "\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df_matches.shape)\n",
    "print(\"\\nFiltered DataFrame (locations with at least one set of coordinates):\")\n",
    "print(df_matches_w_geo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c25d8841-c31c-4b0a-be13-b7505cd3b7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original DataFrame:\n",
      "(812448, 69)\n",
      "\n",
      "Filtered DataFrame (locations with at least one set of coordinates):\n",
      "(312367, 69)\n"
     ]
    }
   ],
   "source": [
    "# find groups that have no georeference\n",
    "# from https://claude.ai/chat/f9eab37d-6cc0-459c-9d24-fd78d6152d10\n",
    "\n",
    "def filter_locations_without_coordinates(df):\n",
    "    \"\"\"\n",
    "    Filter location groups based on having NO coordinates in any record.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with location_string and coordinates columns\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Filtered DataFrame containing all records from location groups\n",
    "                     that have no coordinates at all\n",
    "    \"\"\"\n",
    "    # Group by location_string and check if ALL coordinates are empty for that group\n",
    "    locations_without_coords = df.groupby('bels_location_string').agg({\n",
    "        'decimalLatitude': lambda x: all(pd.isna(x) | (x == ''))\n",
    "    })\n",
    "    \n",
    "    # Get the location strings where the condition is True\n",
    "    locations_no_coords = locations_without_coords[\n",
    "        locations_without_coords['decimalLatitude']\n",
    "    ].index\n",
    "    \n",
    "    # Filter the original DataFrame to keep all records from matching locations\n",
    "    filtered_df = df[df['bels_location_string'].isin(locations_no_coords)]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Filter locations that have at least one set of coordinates\n",
    "#result = filter_locations_with_coordinates(df)\n",
    "df_matches_no_geo = filter_locations_without_coordinates(df_matches)\n",
    "\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df_matches.shape)\n",
    "print(\"\\nFiltered DataFrame (locations with at least one set of coordinates):\")\n",
    "print(df_matches_no_geo.shape)\n",
    "\n",
    "# Print summary\n",
    "#print(\"\\nSummary of locations without any coordinates:\")\n",
    "#for loc in df_matches_wo_geo['bels_location_string'].unique():\n",
    "#    print(f\"- {loc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eda1b94-a599-44da-bf0a-58106ba9dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records with only the state name in bels string\n",
    "#df_nogeo_with_geolocdups_nostates = df_nogeo_with_geolocdups[df_nogeo_with_geolocdups[column1] != df[column2]]\n",
    "\n",
    "#df_nogeo_with_geolocdups_nostates = df_nogeo_with_geolocdups[~df_nogeo_with_geolocdups.apply(lambda row: row['stateProvince'].lower() == row['bels_location_string'].lower(), axis=1)]\n",
    "#df_matches_wo_geo\n",
    "df_no_geo_nostates = df_matches_no_geo[~df_matches_no_geo.apply(lambda row: row['stateProvince'].lower() == row['bels_location_string'].lower(), axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367ad0fd-6c62-424b-85b5-f2cbefc031bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove state + county matches\n",
    "#df_nogeo_with_geolocdups_nostatecounty = df_nogeo_with_geolocdups_nostates[~df_nogeo_with_geolocdups_nostates.apply(lambda row: (str(row['stateProvince']) + str(row['county'])).lower() == row['bels_location_string'].lower(), axis=1)]\n",
    "#df_wo_geo_nostates\n",
    "df_no_geo_nostatecounty = df_no_geo_nostates[~df_no_geo_nostates.apply(lambda row: (str(row['stateProvince']) + str(row['county'])).lower() == row['bels_location_string'].lower(), axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "968bd2a7-0617-419e-a105-944b4a2ff6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_mean(x):\n",
    "    if len(x) <= 1:\n",
    "        return pd.NA\n",
    "    filtered = x[x > 1]\n",
    "    if len(filtered) == 0:\n",
    "        return pd.NA\n",
    "    filtered = filtered[filtered < filtered.max()]\n",
    "    if len(filtered) == 0:\n",
    "        return pd.NA\n",
    "    return filtered.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14db5a8d-fa93-44d8-a924-0e454f9645e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_median(x):\n",
    "    if len(x) <= 1:\n",
    "        return pd.NA\n",
    "    filtered = x[x > 1]\n",
    "    if len(filtered) == 0:\n",
    "        return pd.NA\n",
    "    filtered = filtered[filtered < filtered.max()]\n",
    "    if len(filtered) == 0:\n",
    "        return pd.NA\n",
    "    return filtered.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3685e5e-955d-486b-a634-126ec19d4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_county_names(df, county_column):\n",
    "    \"\"\"\n",
    "    Normalize county names by removing variations of 'County', question marks,\n",
    "    and converting to title case.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing county names\n",
    "    county_column (str): Name of the column containing county names\n",
    "    \n",
    "    Returns:\n",
    "    pandas.Series: Series containing normalized county names\n",
    "    \"\"\"\n",
    "    # Handle None/NaN values first\n",
    "    normalized = df[county_column].fillna('')\n",
    "    \n",
    "    # Convert to string type to ensure string operations work\n",
    "    normalized = normalized.astype(str)\n",
    "    \n",
    "    # Strip whitespace and remove patterns\n",
    "    normalized = normalized.str.strip()\n",
    "    \n",
    "    # Remove various forms of \"County\" and question marks (case insensitive)\n",
    "    patterns = [\n",
    "        (r'\\?+', ''),  # Remove one or more question marks anywhere in the string\n",
    "        (r'\\s*county\\s*$', ''),\n",
    "        (r'\\s*co\\.\\s*$', ''),\n",
    "        (r'\\s*co\\s*$', ''),\n",
    "        (r'\\s*parish\\s*$', '')\n",
    "    ]\n",
    "    \n",
    "    for pattern, replacement in patterns:\n",
    "        normalized = normalized.str.replace(pattern, replacement, case=False, regex=True)\n",
    "    \n",
    "    # Convert to title case and strip any remaining whitespace\n",
    "    normalized = normalized.str.title().str.strip()\n",
    "    \n",
    "    # Replace empty strings back with None/NaN\n",
    "    normalized = normalized.replace('', pd.NA)\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b0a1d97-e621-456b-a7c0-1ffb3b9974a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the normalized county names as a new column\n",
    "df_no_geo_normalized = df_no_geo_nostatecounty.copy()\n",
    "# Add the normalized county names as a new column\n",
    "df_no_geo_normalized.loc[:, 'county_normalized'] = normalize_county_names(df_no_geo_normalized, 'county')\n",
    "#df_no_geo_normalized['county_normalized'] = normalize_county_names(df_no_geo_normalized, 'county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1b1d790-ac90-45cf-b354-7eb8ee1031be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups with coordinates\n",
    "df_w_geo_normalized = df_matches_w_geo.copy()\n",
    "# Add the normalized county names as a new column\n",
    "df_w_geo_normalized.loc[:, 'county_normalized'] = normalize_county_names(df_w_geo_normalized, 'county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "715ea976-647d-4d03-bc6c-2782d9ad4f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>institutionCode</th>\n",
       "      <th>collectionCode</th>\n",
       "      <th>ownerInstitutionCode</th>\n",
       "      <th>collectionID</th>\n",
       "      <th>basisOfRecord</th>\n",
       "      <th>occurrenceID</th>\n",
       "      <th>catalogNumber</th>\n",
       "      <th>otherCatalogNumbers</th>\n",
       "      <th>family</th>\n",
       "      <th>...</th>\n",
       "      <th>bels_location_string</th>\n",
       "      <th>bels_location_id</th>\n",
       "      <th>coord_group_id</th>\n",
       "      <th>coord_group_match_count</th>\n",
       "      <th>bels_group_coord_count</th>\n",
       "      <th>bels_group_rec_count</th>\n",
       "      <th>loc_id</th>\n",
       "      <th>dup_loc_count</th>\n",
       "      <th>recs_w_geo_count</th>\n",
       "      <th>county_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14218981</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fea81a47-2365-45cc-bef9-b6bbff7457e6</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>c00dfba3-4509-4516-8c02-41a4d74d7b02</td>\n",
       "      <td>BRIT217077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Osmundaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texasmorrisdaingerfieldstatepark</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>95194</td>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "      <td>Morris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14218982</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fea81a47-2365-45cc-bef9-b6bbff7457e6</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>b510084b-7011-43b8-953a-4916f5a92d7a</td>\n",
       "      <td>BRIT217409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fabaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texaserathhunewellranch</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>64194</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>Erath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>14219035</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fea81a47-2365-45cc-bef9-b6bbff7457e6</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>9c4331aa-1246-434b-a809-0d6d4b6f8a2e</td>\n",
       "      <td>BRIT217341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fabaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texaserathhunewellranch</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>64194</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>Erath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>14219039</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fea81a47-2365-45cc-bef9-b6bbff7457e6</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>0d575a12-ac2b-48f5-86b0-066dca4a49a2</td>\n",
       "      <td>BRIT217337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fabaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texaserathhunewellrancharea4.</td>\n",
       "      <td>58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>64263</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Erath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>14219042</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>BRIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fea81a47-2365-45cc-bef9-b6bbff7457e6</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>4d4d37ab-5d08-4ada-b640-7668388ae325</td>\n",
       "      <td>BRIT217334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fabaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texascherokeecareylakerd3milesnorthofcuneytx</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52831</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Cherokee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146420</th>\n",
       "      <td>27083785</td>\n",
       "      <td>LL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3433d090-b098-4832-92ff-06b8c4b2edfd</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>fff4ede9-9481-4a93-a482-27a1c8c5434a</td>\n",
       "      <td>LL00492158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ranunculaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texasculberson</td>\n",
       "      <td>2651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>2088</td>\n",
       "      <td>56389</td>\n",
       "      <td>2088</td>\n",
       "      <td>19</td>\n",
       "      <td>Culberson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146422</th>\n",
       "      <td>13436617</td>\n",
       "      <td>LL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3433d090-b098-4832-92ff-06b8c4b2edfd</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>fff5853a-b880-453b-86cb-6db57861f27c</td>\n",
       "      <td>LL00311039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Potamogetonaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texasmenardsansabariverjustnortheastofftmckavett</td>\n",
       "      <td>162378</td>\n",
       "      <td>58697.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>93704</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Menard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146424</th>\n",
       "      <td>30071521</td>\n",
       "      <td>LL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3433d090-b098-4832-92ff-06b8c4b2edfd</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>fff98d6b-5b14-4b2b-a32e-f38b6fc24ea8</td>\n",
       "      <td>LL00566769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lamiaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texasaransasgooseisland</td>\n",
       "      <td>48538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>35413</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>Aransas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146425</th>\n",
       "      <td>13429866</td>\n",
       "      <td>LL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3433d090-b098-4832-92ff-06b8c4b2edfd</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>fffa8fc3-322f-4d7c-9e67-9ea56c4ffbb4</td>\n",
       "      <td>LL00288215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salicaceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texasculbersonoffhighwayus62,alongcreeknorthof...</td>\n",
       "      <td>441212</td>\n",
       "      <td>101792.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57742</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Culberson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146427</th>\n",
       "      <td>13455242</td>\n",
       "      <td>LL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3433d090-b098-4832-92ff-06b8c4b2edfd</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>fffc0db0-8f2c-4da7-ba0c-bc8bb50fdadd</td>\n",
       "      <td>LL00386978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>...</td>\n",
       "      <td>texasculberson25mileswestoforla</td>\n",
       "      <td>169226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>56505</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Culberson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500081 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id institutionCode collectionCode ownerInstitutionCode  \\\n",
       "6        14218981            BRIT           BRIT                  NaN   \n",
       "7        14218982            BRIT           BRIT                  NaN   \n",
       "59       14219035            BRIT           BRIT                  NaN   \n",
       "63       14219039            BRIT           BRIT                  NaN   \n",
       "66       14219042            BRIT           BRIT                  NaN   \n",
       "...           ...             ...            ...                  ...   \n",
       "1146420  27083785              LL            NaN                  NaN   \n",
       "1146422  13436617              LL            NaN                  NaN   \n",
       "1146424  30071521              LL            NaN                  NaN   \n",
       "1146425  13429866              LL            NaN                  NaN   \n",
       "1146427  13455242              LL            NaN                  NaN   \n",
       "\n",
       "                                 collectionID      basisOfRecord  \\\n",
       "6        fea81a47-2365-45cc-bef9-b6bbff7457e6  PreservedSpecimen   \n",
       "7        fea81a47-2365-45cc-bef9-b6bbff7457e6  PreservedSpecimen   \n",
       "59       fea81a47-2365-45cc-bef9-b6bbff7457e6  PreservedSpecimen   \n",
       "63       fea81a47-2365-45cc-bef9-b6bbff7457e6  PreservedSpecimen   \n",
       "66       fea81a47-2365-45cc-bef9-b6bbff7457e6  PreservedSpecimen   \n",
       "...                                       ...                ...   \n",
       "1146420  3433d090-b098-4832-92ff-06b8c4b2edfd  PreservedSpecimen   \n",
       "1146422  3433d090-b098-4832-92ff-06b8c4b2edfd  PreservedSpecimen   \n",
       "1146424  3433d090-b098-4832-92ff-06b8c4b2edfd  PreservedSpecimen   \n",
       "1146425  3433d090-b098-4832-92ff-06b8c4b2edfd  PreservedSpecimen   \n",
       "1146427  3433d090-b098-4832-92ff-06b8c4b2edfd  PreservedSpecimen   \n",
       "\n",
       "                                 occurrenceID catalogNumber  \\\n",
       "6        c00dfba3-4509-4516-8c02-41a4d74d7b02    BRIT217077   \n",
       "7        b510084b-7011-43b8-953a-4916f5a92d7a    BRIT217409   \n",
       "59       9c4331aa-1246-434b-a809-0d6d4b6f8a2e    BRIT217341   \n",
       "63       0d575a12-ac2b-48f5-86b0-066dca4a49a2    BRIT217337   \n",
       "66       4d4d37ab-5d08-4ada-b640-7668388ae325    BRIT217334   \n",
       "...                                       ...           ...   \n",
       "1146420  fff4ede9-9481-4a93-a482-27a1c8c5434a    LL00492158   \n",
       "1146422  fff5853a-b880-453b-86cb-6db57861f27c    LL00311039   \n",
       "1146424  fff98d6b-5b14-4b2b-a32e-f38b6fc24ea8    LL00566769   \n",
       "1146425  fffa8fc3-322f-4d7c-9e67-9ea56c4ffbb4    LL00288215   \n",
       "1146427  fffc0db0-8f2c-4da7-ba0c-bc8bb50fdadd    LL00386978   \n",
       "\n",
       "        otherCatalogNumbers            family  ...  \\\n",
       "6                       NaN       Osmundaceae  ...   \n",
       "7                       NaN          Fabaceae  ...   \n",
       "59                      NaN          Fabaceae  ...   \n",
       "63                      NaN          Fabaceae  ...   \n",
       "66                      NaN          Fabaceae  ...   \n",
       "...                     ...               ...  ...   \n",
       "1146420                 NaN     Ranunculaceae  ...   \n",
       "1146422                 NaN  Potamogetonaceae  ...   \n",
       "1146424                 NaN         Lamiaceae  ...   \n",
       "1146425                 NaN        Salicaceae  ...   \n",
       "1146427                 NaN        Asteraceae  ...   \n",
       "\n",
       "                                      bels_location_string  bels_location_id  \\\n",
       "6                         texasmorrisdaingerfieldstatepark                 6   \n",
       "7                                  texaserathhunewellranch                 7   \n",
       "59                                 texaserathhunewellranch                 7   \n",
       "63                           texaserathhunewellrancharea4.                58   \n",
       "66            texascherokeecareylakerd3milesnorthofcuneytx                61   \n",
       "...                                                    ...               ...   \n",
       "1146420                                     texasculberson              2651   \n",
       "1146422   texasmenardsansabariverjustnortheastofftmckavett            162378   \n",
       "1146424                            texasaransasgooseisland             48538   \n",
       "1146425  texasculbersonoffhighwayus62,alongcreeknorthof...            441212   \n",
       "1146427                    texasculberson25mileswestoforla            169226   \n",
       "\n",
       "        coord_group_id coord_group_match_count  bels_group_coord_count  \\\n",
       "6                  NaN                     NaN                      25   \n",
       "7                  2.0                   104.0                      79   \n",
       "59                 2.0                   104.0                      79   \n",
       "63                 2.0                   104.0                       3   \n",
       "66                 NaN                     NaN                       1   \n",
       "...                ...                     ...                     ...   \n",
       "1146420            NaN                     NaN                      19   \n",
       "1146422        58697.0                     5.0                       4   \n",
       "1146424            NaN                     NaN                       6   \n",
       "1146425       101792.0                     2.0                       2   \n",
       "1146427            NaN                     NaN                       1   \n",
       "\n",
       "        bels_group_rec_count loc_id dup_loc_count recs_w_geo_count  \\\n",
       "6                        200  95194           200               25   \n",
       "7                         79  64194            79               79   \n",
       "59                        79  64194            79               79   \n",
       "63                         3  64263             3                3   \n",
       "66                         3  52831             3                1   \n",
       "...                      ...    ...           ...              ...   \n",
       "1146420                 2088  56389          2088               19   \n",
       "1146422                    7  93704             7                4   \n",
       "1146424                   38  35413            38                6   \n",
       "1146425                    2  57742             2                2   \n",
       "1146427                   18  56505            18                1   \n",
       "\n",
       "        county_normalized  \n",
       "6                  Morris  \n",
       "7                   Erath  \n",
       "59                  Erath  \n",
       "63                  Erath  \n",
       "66               Cherokee  \n",
       "...                   ...  \n",
       "1146420         Culberson  \n",
       "1146422            Menard  \n",
       "1146424           Aransas  \n",
       "1146425         Culberson  \n",
       "1146427         Culberson  \n",
       "\n",
       "[500081 rows x 71 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_geo_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b35e43b9-5482-45d9-af0c-2342959bd0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_geo_normalized_means = calculate_and_add_county_means(df_no_geo_normalized, 'dup_loc_count', 'county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cef55ee-bc01-4420-be11-669250d6d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean only\n",
    "#county_summary_v1 = df_no_geo_normalized.groupby(['stateProvince', 'county_normalized']).agg(\n",
    "county_summary = df_no_geo_normalized.groupby(['stateProvince', 'county_normalized']).agg(\n",
    "    total_locations=('loc_id', 'count'),\n",
    "    unique_locations=('loc_id', 'nunique'),\n",
    "    dup_loc_count=('dup_loc_count', 'max'),\n",
    "    regular_mean=('dup_loc_count', 'mean'),\n",
    "    filtered_mean=('dup_loc_count', filtered_mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e197a825-c3d2-41ee-a1a2-7577dbf306a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary with filtered and regular mean and median\n",
    "county_summary_no_geo = df_no_geo_normalized.groupby(['stateProvince', 'county_normalized']).agg(\n",
    "    total_locations=('loc_id', 'count'),\n",
    "    unique_locations=('loc_id', 'nunique'),\n",
    "    dup_loc_count=('dup_loc_count', 'max'),\n",
    "    regular_mean=('dup_loc_count', 'mean'),\n",
    "    filtered_mean=('dup_loc_count', filtered_mean),\n",
    "    regular_median=('dup_loc_count', 'median'),\n",
    "    filtered_median=('dup_loc_count', filtered_median)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2b01439-db57-4e92-8ed1-b7b97bdba928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert filtered_mean to float and then round\n",
    "county_summary_no_geo['filtered_mean'] = pd.to_numeric(county_summary['filtered_mean']).round(2)\n",
    "county_summary_no_geo['regular_mean'] = county_summary['regular_mean'].round(2)\n",
    "#county_summary['filtered_mean'] = county_summary['filtered_mean'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e47802bb-746e-4403-951d-c515490b55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add summary to groups with coords\n",
    "#summary with filtered and regular mean and median\n",
    "county_summary_w_geo = df_w_geo_normalized.groupby(['stateProvince', 'county_normalized']).agg(\n",
    "    total_locations=('loc_id', 'count'),\n",
    "    unique_locations=('loc_id', 'nunique'),\n",
    "    dup_loc_count=('dup_loc_count', 'max'),\n",
    "    regular_mean=('dup_loc_count', 'mean'),\n",
    "    filtered_mean=('dup_loc_count', filtered_mean),\n",
    "    regular_median=('dup_loc_count', 'median'),\n",
    "    filtered_median=('dup_loc_count', filtered_median)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2cfde99-f837-4add-8ff0-799fd4b7ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_county_status(county_summary):\n",
    "    \"\"\"\n",
    "    Update county_summary DataFrame with status based on county lists in text files\n",
    "    for Texas and Oklahoma.\n",
    "    \n",
    "    Parameters:\n",
    "    county_summary (pandas.DataFrame): DataFrame with county summary data indexed by state and county\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Updated county_summary DataFrame with new status column\n",
    "    \"\"\"\n",
    "    # File paths for each state\n",
    "    state_files = {\n",
    "        'Texas': {\n",
    "            #'assigned': '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/texas_counties_assigned.txt',\n",
    "            'assigned': '/media/jbest/data3/BRIT_git/TORCH_georeferencing/texas_counties_assigned.txt',\n",
    "            #'not_assigned': '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/texas_counties_not_assigned.txt'\n",
    "            'not_assigned': '/media/jbest/data3/BRIT_git/TORCH_georeferencing/texas_counties_not_assigned.txt'\n",
    "        },\n",
    "        'Oklahoma': {\n",
    "            #'assigned': '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/oklahoma_counties_assigned.txt',\n",
    "            'assigned': '/media/jbest/data3/BRIT_git/TORCH_georeferencing/oklahoma_counties_assigned.txt',\n",
    "            #'not_assigned': '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/oklahoma_counties_not_assigned.txt'\n",
    "            'not_assigned': '/media/jbest/data3/BRIT_git/TORCH_georeferencing/oklahoma_counties_not_assigned.txt'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    result_df = county_summary.copy()\n",
    "    \n",
    "    # Add status column initialized with None\n",
    "    result_df['status'] = None\n",
    "    \n",
    "    # Load and process each state's counties\n",
    "    for state, files in state_files.items():\n",
    "        # Read assigned counties\n",
    "        try:\n",
    "            with open(files['assigned'], 'r') as f:\n",
    "                assigned_counties = set(line.strip().lower() for line in f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Could not find assigned counties file for {state}\")\n",
    "            assigned_counties = set()\n",
    "            \n",
    "        # Read not assigned counties\n",
    "        try:\n",
    "            with open(files['not_assigned'], 'r') as f:\n",
    "                not_assigned_counties = set(line.strip().lower() for line in f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Could not find not-assigned counties file for {state}\")\n",
    "            not_assigned_counties = set()\n",
    "        \n",
    "        # Update status for this state's counties\n",
    "        state_mask = result_df.index.get_level_values('stateProvince') == state\n",
    "        for idx in result_df[state_mask].index:\n",
    "            county_name = idx[1].lower()  # Access county name from MultiIndex\n",
    "            if county_name in assigned_counties:\n",
    "                result_df.at[idx, 'status'] = 'assigned'\n",
    "            elif county_name in not_assigned_counties:\n",
    "                result_df.at[idx, 'status'] = 'not assigned'\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfb94228-a7ee-4cb5-8292-13bb99c23eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not_assigned_file = '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/texas_counties_not_assigned.txt'\n",
    "#assigned_file = '/mnt/DATA3-4TB/BRIT_git/TORCH_georeferencing/texas_counties_assigned.txt'\n",
    "#county_summary_status = update_county_status(county_summary, assigned_file, not_assigned_file)\n",
    "county_summary_no_geo_status = update_county_status(county_summary_no_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb4a639e-eacc-4db4-9229-f2f72657fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_summary_w_geo_status = update_county_status(county_summary_w_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7b7dc81-3ca9-465f-9a3c-d04d89e1b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_summary_no_geo_status.to_csv('TORCH_no_geo_county_summary.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4965032-a619-46cb-b55b-87db89ae7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_summary_w_geo_status.to_csv('TORCH_w_geo_county_summary.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "795aa96b-2e6e-45e5-bf8f-bd41cb5bc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with geo export\n",
    "df_matches_w_geo.to_csv('TORCH_w_geo.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6c5975b-0f5f-4ac4-a7c2-30635843facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texas only\n",
    "df_matches_tx_w_geo = df_matches_w_geo[(df_matches_w_geo['stateProvince'] == 'Texas')]\n",
    "df_matches_tx_w_geo.to_csv('TORCH_TX_w_geo.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6bf28a6-3985-4b59-8ed0-ee144854e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oklahoma only\n",
    "df_matches_ok_w_geo = df_matches_w_geo[(df_matches_w_geo['stateProvince'] == 'Oklahoma')]\n",
    "df_matches_ok_w_geo.to_csv('TORCH_OK_w_geo.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3a651-f003-4a14-a98a-55c79471e2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
